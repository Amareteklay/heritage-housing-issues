{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Cleaning Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Generate cleaned data by handling missing values and transforming variables\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousePrices.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Cleaned data in outputs/datasets/cleaned\n",
        "* Data cleaning pipline\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* Several variables have missing values\n",
        "* Two variables have more than 80% missing values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/heritage-housing-issues/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/heritage-housing-issues'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>...</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "3       961       NaN           NaN           No         216          ALQ   \n",
              "4      1145       NaN           4.0           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
              "0        150            0.0         548          RFn  ...         65.0   \n",
              "1        284            NaN         460          RFn  ...         80.0   \n",
              "2        434            0.0         608          RFn  ...         68.0   \n",
              "3        540            NaN         642          Unf  ...         60.0   \n",
              "4        490            0.0         836          RFn  ...         84.0   \n",
              "\n",
              "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
              "0       196.0          61            5            7          856         0.0   \n",
              "1         0.0           0            8            6         1262         NaN   \n",
              "2       162.0          42            5            7          920         NaN   \n",
              "3         0.0          35            5            7          756         NaN   \n",
              "4       350.0          84            5            8         1145         NaN   \n",
              "\n",
              "   YearBuilt  YearRemodAdd  SalePrice  \n",
              "0       2003          2003     208500  \n",
              "1       1976          1976     181500  \n",
              "2       2001          2002     223500  \n",
              "3       1915          1970     140000  \n",
              "4       2000          2000     250000  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/collection/HousePrices.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the quick display of the first five rows of our dataframe object above, we already see several cells with missing values. Here we dig deeper and get all variables that have missing values.\n",
        " * Nine out of 24 variables (which is 75% of the columns) have missing values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2ndFlrSF',\n",
              " 'BedroomAbvGr',\n",
              " 'BsmtFinType1',\n",
              " 'EnclosedPorch',\n",
              " 'GarageFinish',\n",
              " 'GarageYrBlt',\n",
              " 'LotFrontage',\n",
              " 'MasVnrArea',\n",
              " 'WoodDeckSF']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 9 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   2ndFlrSF       1374 non-null   float64\n",
            " 1   BedroomAbvGr   1361 non-null   float64\n",
            " 2   BsmtFinType1   1346 non-null   object \n",
            " 3   EnclosedPorch  136 non-null    float64\n",
            " 4   GarageFinish   1298 non-null   object \n",
            " 5   GarageYrBlt    1379 non-null   float64\n",
            " 6   LotFrontage    1201 non-null   float64\n",
            " 7   MasVnrArea     1452 non-null   float64\n",
            " 8   WoodDeckSF     155 non-null    float64\n",
            "dtypes: float64(7), object(2)\n",
            "memory usage: 102.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df[vars_with_missing_data].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Assessing the distributions of numerical variables with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "for col in vars_with_missing_data:\n",
        "  if df[col].dtypes == 'float64':\n",
        "    sns.histplot(data=df, x=col, kde=True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Profile Report\n",
        "\n",
        "* We generate pandas profiling report for each variable with missing values.\n",
        "  * We import pandas_profiling library and generate a profile report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code from walkthrough project 02, data cleaning notebook\n",
        "from pandas_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Custom function to display missing data levels in a dataframe, it shows the aboslute levels, relative levels and data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "  missing_data_absolute = df.isnull().sum()\n",
        "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
        "  df_missing_data = (pd.DataFrame(\n",
        "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                 \"DataType\":df.dtypes}\n",
        "                                  )\n",
        "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check missing data levels for collected dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Handling Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Defining DataCleaningEffect() function\n",
        "  * Code copied and adapted from Unit 9 of the feature engine lesson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Summary\n",
        "* Drop ['EnclosedPorch', 'WoodDeckSF'] because each has more than 80% missing values.\n",
        "* Imputation\n",
        "   * Mean- ['LotFrontage', 'BedroomAbvGr' ]\n",
        "   * Median- ['2ndFlrSF', 'GarageYrBlt', 'MasVnrArea' ]\n",
        "   * Categorical- ['GarageFinish','BsmtFinType1' ] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer, MeanMedianImputer, CategoricalImputer\n",
        "from feature_engine.selection import DropFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_mean = ['LotFrontage' , 'BedroomAbvGr']\n",
        "imputer = MeanMedianImputer(imputation_method='mean', variables=variables_mean)\n",
        "df_method = imputer.fit_transform(df)\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_median = ['2ndFlrSF' , 'GarageYrBlt', 'MasVnrArea']\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables_median)\n",
        "df_method = imputer.fit_transform(df)\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_categorical = ['GarageFinish' , 'BsmtFinType1']\n",
        "imputer = CategoricalImputer(imputation_method='missing', fill_value='Missing', variables=variables_categorical)\n",
        "df_method = imputer.fit_transform(df)\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "      ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['LotFrontage' , 'BedroomAbvGr']) ),\n",
        "      ( 'median',  MeanMedianImputer(imputation_method='median',\n",
        "                                     variables=['2ndFlrSF' , 'GarageYrBlt', 'MasVnrArea']) ),\n",
        "      ( 'categorical',  CategoricalImputer(imputation_method='missing',\n",
        "                                     fill_value='Missing',\n",
        "                                     variables=['GarageFinish' , 'BsmtFinType1']) ),\n",
        "      ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch' , 'WoodDeckSF']) )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pipeline.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# profile = ProfileReport(df=df, minimal=True)\n",
        "# profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section for \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned')\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"outputs/datasets/cleaned/HousePricesCleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
